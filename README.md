# Projet de D√©monstration Kafka avec Go

Ce projet est une d√©monstration d'un syst√®me de messagerie bas√© sur Apache Kafka, enti√®rement conteneuris√© avec Docker. Il illustre plusieurs patrons d'architecture orient√©e √©v√©nements (EDA) et bonnes pratiques de production √† travers un cas d'utilisation simple : un producteur qui g√©n√®re des commandes enrichies et un consommateur qui les traite de mani√®re autonome et observable.

## Patrons d'Architecture et Bonnes Pratiques

Ce projet met en ≈ìuvre plusieurs patrons et pratiques essentiels pour les syst√®mes distribu√©s.

### 1. Event-Driven Architecture (EDA)
Le syst√®me est enti√®rement pilot√© par les √©v√©nements. Le producteur et le consommateur ne communiquent pas directement, mais via des √©v√©nements (messages de commande) stock√©s dans Kafka. Cela favorise le d√©couplage, la scalabilit√© et la r√©silience.

### 2. Publisher/Subscriber
Le mod√®le de communication est le Pub/Sub. Le `producer.go` publie des messages dans le topic `orders` sans savoir qui les consommera. Le `tracker.go` s'abonne √† ce topic pour recevoir les messages, permettant √† plusieurs consommateurs de traiter les m√™mes messages en parall√®le si n√©cessaire.

### 3. Event Carried State Transfer
C'est le patron de conception de message le plus important de ce projet. Chaque message de commande est **enrichi avec toutes les donn√©es n√©cessaires √† son traitement** (informations client, d√©tails de l'inventaire, etc.). Le consommateur est ainsi **autonome** et n'a pas besoin d'interroger d'autres services, ce qui r√©duit les d√©pendances et am√©liore la latence. Le mod√®le de donn√©es est d√©fini dans `order.go`.

### 4. Audit Trail (Piste d'Audit)
Le fichier `tracker.events` impl√©mente ce patron en cr√©ant un **journal immuable de chaque message re√ßu**. Qu'un message soit valide ou corrompu, il est enregistr√©. Cette pratique est cruciale pour :
-   L'**audit** : Conserver une preuve de toutes les donn√©es entrantes.
-   Le **d√©bogage** : Analyser les messages qui ont caus√© des erreurs.
-   La **relecture** : Permettre de rejouer des s√©quences d'√©v√©nements pour des tests ou une reprise sur erreur.

### 5. Application Health Monitoring
Le fichier `tracker.log` est d√©di√© √† la surveillance de la sant√© de l'application. Il contient des **logs structur√©s (JSON)** sur les √©v√©nements de cycle de vie (d√©marrage, arr√™t), les erreurs et les **m√©triques p√©riodiques** (d√©bit de messages, taux de succ√®s). Ce flux de donn√©es est con√ßu pour alimenter des dashboards, des syst√®mes d'alerte et des outils d'analyse de logs.

### 6. Guaranteed Delivery (Livraison Garantie)
Le `producer.go` ne se contente pas d'envoyer les messages "√† l'aveugle". Il √©coute les accus√©s de r√©ception (delivery reports) de Kafka pour s'assurer que chaque message a bien √©t√© re√ßu et stock√© par le broker. La fonction `deliveryReport` dans `producer.go` est responsable de ce suivi.

### 7. Graceful Shutdown (Arr√™t Propre)
Le `producer.go` et le `tracker.go` interceptent les signaux du syst√®me (comme `Ctrl+C`).
-   Le **producteur** utilise `producer.Flush()` pour envoyer tous les messages qui sont encore dans son tampon.
-   Le **consommateur** termine sa boucle de traitement et ferme proprement sa connexion.
Cela √©vite la perte de donn√©es lors des arr√™ts planifi√©s ou des d√©ploiements.

### 8. Gestion Robuste des Processus
Les scripts `start.sh` et `stop.sh` utilisent des fichiers PID (`.pid`) pour une gestion pr√©cise des processus. Cela garantit que les signaux d'arr√™t sont envoy√©s aux bons processus, √©vitant ainsi les arr√™ts accidentels ou incomplets.

## Strat√©gie d'Observabilit√©

Le syst√®me utilise une strat√©gie de journalisation √† deux fichiers pour s√©parer les pr√©occupations, en s'appuyant sur les patrons d√©crits ci-dessus :

1.  **`tracker.log` : Journal d'Observabilit√© (`Application Health Monitoring`)**
    -   **Quoi ?** √âv√©nements de cycle de vie, m√©triques p√©riodiques, et erreurs critiques.
    -   **Pourquoi ?** Pour le **monitoring** et l'**alerte**.

2.  **`tracker.events` : Journal de Tra√ßabilit√© (`Audit Trail`)**
    -   **Quoi ?** Une copie de **chaque message** re√ßu de Kafka.
    -   **Pourquoi ?** Pour l'**audit**, le **d√©bogage** et la **relecture**.

## Pr√©requis

-   **Docker** & **Docker Compose**
-   **Go 1.22+**
-   Optionnel : `jq` pour une analyse avanc√©e des logs JSON.

## üöÄ D√©marrage Rapide

1.  **D√©marrer l'environnement :**
    ```bash
    ./start.sh
    ```
    Ce script lance Kafka, cr√©e le topic, et ex√©cute le producteur et le consommateur.

2.  **Observer les journaux :**
    Ouvrez deux autres terminaux pour suivre les journaux en temps r√©el :
    ```bash
    # Suivre les logs syst√®me (Application Health Monitoring)
    tail -f tracker.log | jq

    # Suivre tous les messages entrants (Audit Trail)
    tail -f tracker.events | jq
    ```

3.  **Lancer le Moniteur Interactif (Optionnel) :**
    Pour une vue d'ensemble en temps r√©el, lancez le moniteur de logs :
    ```bash
    go run log_monitor.go
    ```

4.  **Arr√™ter l'environnement :**
    ```bash
    ./stop.sh
    ```
    Ce script arr√™te proprement les applications Go, puis les conteneurs Docker.

## Structure du Code

-   **`order.go`** : D√©finit le mod√®le de donn√©es partag√© (Event Carried State Transfer).
-   **`producer.go`** : Le code source du producteur.
-   **`tracker.go`** : Le code source du consommateur.
-   **`log_monitor.go`** : L'interface utilisateur du moniteur de logs.
-   **`docker-compose.yaml`** : D√©finit le service Kafka.
-   **`start.sh` / `stop.sh`** : Scripts pour g√©rer le cycle de vie de l'application.

## Commandes Kafka Utiles

-   **Lister les topics :**
    ```bash
    docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list
    ```

-   **Consommer les messages depuis le terminal (pour le d√©bogage) :**
    ```bash
    docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic orders --from-beginning
    ```
