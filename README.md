# Pub-Sub avec Kafka et Python

Ce projet est un exemple Ã©ducatif d'implÃ©mentation du pattern **Pub-Sub (Publisher-Subscriber)** en utilisant **Apache Kafka** et **Python**.

## ğŸ“‹ PrÃ©requis

- Python 3.7 ou supÃ©rieur
- Apache Kafka installÃ© et en cours d'exÃ©cution (localement ou Ã  distance)

### Installation de Kafka (optionnel)

Si vous n'avez pas Kafka installÃ©, vous pouvez utiliser Docker :

```bash
# DÃ©marrer Kafka avec Docker Compose
docker-compose up -d
```

Ou installer Kafka manuellement depuis [kafka.apache.org](https://kafka.apache.org/downloads)

## ğŸš€ Installation

1. Installer les dÃ©pendances Python :

```bash
pip install -r requirements.txt
```

## ğŸ“– Utilisation

### 1. DÃ©marrer le consommateur

Dans un premier terminal, dÃ©marrez le consommateur qui Ã©coutera les messages :

```bash
python consommateur.py
```

### 2. Envoyer des messages avec le producteur

Dans un second terminal, lancez le producteur pour envoyer des messages :

```bash
python producteur.py
```

Vous devriez voir les messages apparaÃ®tre dans le terminal du consommateur !

## ğŸ”§ Configuration

Vous pouvez modifier les paramÃ¨tres par dÃ©faut dans les fichiers :

- **Bootstrap servers** : Adresse du serveur Kafka (par dÃ©faut: `localhost:9092`)
- **Topic** : Nom du topic Kafka (par dÃ©faut: `mon-topic`)
- **Group ID** : ID du groupe de consommateurs (par dÃ©faut: `mon-groupe-consommateur`)

### Exemple de personnalisation

```python
# Dans producteur.py ou consommateur.py
BOOTSTRAP_SERVERS = 'kafka.example.com:9092'
TOPIC = 'mon-topic-personnalise'
```

## ğŸ“š Concepts expliquÃ©s

### Producteur (Publisher)
- **RÃ´le** : Envoie des messages vers un topic Kafka
- **FonctionnalitÃ©s** :
  - SÃ©rialisation JSON des messages
  - Gestion des clÃ©s pour le partitionnement
  - Retry automatique en cas d'Ã©chec
  - Confirmation de rÃ©ception (acks='all')

### Consommateur (Subscriber)
- **RÃ´le** : Lit les messages depuis un topic Kafka
- **FonctionnalitÃ©s** :
  - DÃ©sÃ©rialisation JSON des messages
  - Gestion des groupes de consommateurs
  - Commit automatique des offsets
  - Consommation en continu ou limitÃ©e

## ğŸ¯ Pattern Pub-Sub

Le pattern **Pub-Sub** permet :
- **DÃ©couplage** : Les producteurs et consommateurs ne se connaissent pas directement
- **ScalabilitÃ©** : Plusieurs consommateurs peuvent lire les mÃªmes messages
- **FiabilitÃ©** : Les messages sont persistÃ©s et peuvent Ãªtre relus
- **Distribution** : Les messages peuvent Ãªtre distribuÃ©s sur plusieurs partitions

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ producteur.py      # Script du producteur Kafka
â”œâ”€â”€ consommateur.py    # Script du consommateur Kafka
â”œâ”€â”€ requirements.txt   # DÃ©pendances Python
â””â”€â”€ README.md         # Documentation
```

## ğŸ› DÃ©pannage

### Erreur de connexion Ã  Kafka

VÃ©rifiez que Kafka est bien dÃ©marrÃ© :

```bash
# VÃ©rifier si Kafka Ã©coute sur le port 9092
netstat -an | grep 9092
```

### Topic n'existe pas

Kafka crÃ©era automatiquement le topic si l'option `auto.create.topics.enable=true` est activÃ©e (par dÃ©faut).

Sinon, crÃ©ez-le manuellement :

```bash
kafka-topics.sh --create --topic mon-topic --bootstrap-server localhost:9092
```

## ğŸ“– Ressources

- [Documentation Kafka](https://kafka.apache.org/documentation/)
- [kafka-python Documentation](https://kafka-python.readthedocs.io/)
