# SystÃ¨me Pub-Sub avec Kafka et Python

Exemple Ã©ducatif implÃ©mentant le patron d'architecture **Publish-Subscribe (Pub-Sub)** utilisant Apache Kafka et Python.

## ğŸ“‹ Description

Ce projet dÃ©montre le fonctionnement du patron Pub-Sub avec :
- **`producteur.py`** : Publie des messages vers un topic Kafka
- **`consommateur.py`** : Souscrit et consomme des messages depuis un topic Kafka

## ğŸ¯ Objectifs pÃ©dagogiques

- Comprendre le patron d'architecture Pub-Sub
- DÃ©couvrir Apache Kafka comme systÃ¨me de messagerie distribuÃ©
- Apprendre Ã  crÃ©er des producteurs et consommateurs Kafka en Python
- Observer le partitionnement et le load balancing des messages

## ğŸ“¦ PrÃ©requis

### 1. Apache Kafka

Vous devez avoir Apache Kafka installÃ© et dÃ©marrÃ©. 

#### Installation rapide avec Docker :

```bash
# TÃ©lÃ©charger et dÃ©marrer Kafka avec Docker Compose
docker-compose up -d
```

#### Ou avec Docker directement :

```bash
# 1. DÃ©marrer Zookeeper
docker run -d --name zookeeper -p 2181:2181 zookeeper:latest

# 2. DÃ©marrer Kafka
docker run -d --name kafka -p 9092:9092 \
  --link zookeeper:zookeeper \
  -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
  confluentinc/cp-kafka:latest
```

### 2. Python et dÃ©pendances

```bash
# Python 3.7 ou supÃ©rieur
python3 --version

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸš€ Utilisation

### Ã‰tape 1 : DÃ©marrer le consommateur

Dans un terminal, lancez le consommateur (il va attendre les messages) :

```bash
python3 consommateur.py
```

Le consommateur affichera :
- Les mÃ©tadonnÃ©es de chaque message reÃ§u (topic, partition, offset)
- Le contenu complet du message au format JSON

### Ã‰tape 2 : DÃ©marrer le producteur

Dans un **autre terminal**, lancez le producteur :

```bash
python3 producteur.py
```

Le producteur va :
- Envoyer 10 messages de dÃ©monstration
- Afficher la confirmation d'envoi pour chaque message
- Utiliser diffÃ©rentes clÃ©s pour montrer le partitionnement

### Observation

Vous devriez voir :
1. Le producteur envoie des messages toutes les secondes
2. Le consommateur reÃ§oit et affiche ces messages en temps rÃ©el
3. Les mÃ©tadonnÃ©es montrent comment Kafka gÃ¨re les messages (partitions, offsets)

## ğŸ”§ Configuration

### Modifier le serveur Kafka

Dans les deux fichiers, changez la variable `KAFKA_SERVER` :

```python
KAFKA_SERVER = 'localhost:9092'  # Votre serveur Kafka
```

### Modifier le topic

```python
TOPIC = 'demo-topic'  # Nom de votre topic
```

### Modifier le groupe de consommateurs

Dans `consommateur.py` :

```python
GROUP_ID = 'demo-group'  # Identifiant du groupe
```

## ğŸ“ Concepts clÃ©s

### Patron Pub-Sub

- **DÃ©couplage** : Le producteur et le consommateur ne se connaissent pas
- **Asynchrone** : Les messages sont traitÃ©s de maniÃ¨re asynchrone
- **ScalabilitÃ©** : Plusieurs consommateurs peuvent traiter les messages en parallÃ¨le

### Kafka

- **Topic** : Canal de communication pour les messages
- **Partition** : Division d'un topic pour la parallÃ©lisation
- **Offset** : Position d'un message dans une partition
- **Consumer Group** : Groupe de consommateurs qui se partagent les messages

### Partitionnement

Les messages avec la mÃªme clÃ© vont dans la mÃªme partition, garantissant l'ordre de traitement pour ces messages.

## ğŸ§ª ExpÃ©rimentations suggÃ©rÃ©es

### 1. Multiple Consommateurs (Load Balancing)

Lancez plusieurs instances du consommateur dans des terminaux diffÃ©rents :

```bash
# Terminal 1
python3 consommateur.py

# Terminal 2
python3 consommateur.py

# Terminal 3
python3 consommateur.py
```

Avec le mÃªme `GROUP_ID`, Kafka distribuera automatiquement les messages entre les consommateurs.

### 2. DiffÃ©rents groupes (Broadcasting)

Modifiez le `GROUP_ID` dans diffÃ©rentes instances. Chaque groupe recevra **tous** les messages.

### 3. Persistance

ArrÃªtez le consommateur, envoyez des messages avec le producteur, puis redÃ©marrez le consommateur. Les messages seront toujours traitÃ©s grÃ¢ce Ã  la persistance de Kafka.

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚         â”‚                 â”‚         â”‚              â”‚
â”‚ Producteur  â”‚ â”€â”€â”€â”€â–¶   â”‚  Kafka Broker   â”‚  â”€â”€â”€â”€â–¶  â”‚ Consommateur â”‚
â”‚ (Publish)   â”‚         â”‚  (Topic/Queue)  â”‚         â”‚ (Subscribe)  â”‚
â”‚             â”‚         â”‚                 â”‚         â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de donnÃ©es

1. Le **producteur** publie des messages vers un **topic** Kafka
2. Kafka stocke les messages dans des **partitions**
3. Les **consommateurs** s'abonnent au topic et consomment les messages
4. Kafka gÃ¨re automatiquement le **load balancing** entre les consommateurs d'un mÃªme groupe

## ğŸ› ï¸ FonctionnalitÃ©s avancÃ©es

### Producteur

- âœ… SÃ©rialisation JSON automatique
- âœ… Gestion des erreurs et retry
- âœ… Confirmation de livraison (acks='all')
- âœ… ClÃ©s pour le partitionnement
- âœ… Logging dÃ©taillÃ©

### Consommateur

- âœ… DÃ©sÃ©rialisation JSON automatique
- âœ… Commit automatique des offsets
- âœ… Lecture depuis le dÃ©but (earliest)
- âœ… Gestion gracieuse de l'arrÃªt (Ctrl+C)
- âœ… Support pour consumer groups
- âœ… Logging dÃ©taillÃ©

## ğŸ“š Pour aller plus loin

### AmÃ©liorations possibles

1. **Gestion d'erreurs avancÃ©e** : Dead letter queue pour les messages en Ã©chec
2. **SchÃ©mas** : Utiliser Apache Avro pour valider la structure des messages
3. **Monitoring** : IntÃ©grer Prometheus pour surveiller les mÃ©triques
4. **SÃ©curitÃ©** : Ajouter l'authentification SSL/SASL
5. **Transactions** : Garantir l'exactitude des traitements (exactly-once semantics)

### Ressources

- [Documentation Apache Kafka](https://kafka.apache.org/documentation/)
- [kafka-python Documentation](https://kafka-python.readthedocs.io/)
- [Confluent Kafka Tutorials](https://kafka-tutorials.confluent.io/)

## ğŸ“ Licence

Ce projet est Ã  usage Ã©ducatif uniquement.

## ğŸ¤ Contribution

N'hÃ©sitez pas Ã  expÃ©rimenter et modifier le code pour mieux comprendre Kafka !

---

**Bon apprentissage ! ğŸ“**
