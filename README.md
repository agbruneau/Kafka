# Projet de D√©monstration Kafka avec Go

Ce projet est une d√©monstration d'un syst√®me de messagerie bas√© sur Apache Kafka, enti√®rement conteneuris√© avec Docker. Il illustre un cas d'utilisation fondamental avec le patron "Event Carried State Transfer" : un producteur qui g√©n√®re des commandes enrichies et un consommateur qui les traite de mani√®re autonome.

## Architecture

L'architecture est simple et d√©coupl√©e. Le producteur envoie des messages contenant un √©tat complet, permettant au consommateur de fonctionner sans d√©pendances externes.

```mermaid
graph TD;
    subgraph "Syst√®me"
        A[Producer en Go] -->|Envoie messages JSON| B(Kafka Topic: orders);
        B -->|Consomme messages| C[Consumer 'Tracker' en Go];
    end

    subgraph "Observabilit√©"
        C --> D[üìÑ tracker.log<br>Logs syst√®me, M√©triques, Erreurs];
        C --> E[üìã tracker.events<br>Journal de tous les messages re√ßus];
    end

    style A fill:#D5E8D4,stroke:#82B366
    style C fill:#D5E8D4,stroke:#82B366
    style B fill:#DAE8FC,stroke:#6C8EBF
    style D fill:#F8CECC,stroke:#B85450
    style E fill:#F8CECC,stroke:#B85450
```

-   **Producteur (`producer.go`)** : G√©n√®re des commandes simul√©es avec un √©tat complet (infos client, inventaire) et les envoie au topic Kafka.
-   **Apache Kafka** : Broker de messages, tournant dans un conteneur Docker. Version `confluentinc/cp-kafka:7.8.3`.
-   **Consommateur (`tracker.go`)** : S'abonne au topic, re√ßoit les commandes et les traite. Il maintient une double journalisation pour l'observabilit√© et la tra√ßabilit√©.

## Pr√©requis

-   **Docker** & **Docker Compose**
-   **Go 1.22+**
-   Optionnel : `jq` pour une analyse avanc√©e des logs JSON.

## üöÄ D√©marrage Rapide

1.  **D√©marrer l'environnement :**
    ```bash
    ./start.sh
    ```
    Ce script lance Kafka, cr√©e le topic, et ex√©cute le producteur et le consommateur.

2.  **Observer les journaux :**
    Ouvrez deux autres terminaux pour suivre les journaux en temps r√©el :
    ```bash
    # Suivre les logs syst√®me (m√©triques, erreurs)
    tail -f tracker.log | jq

    # Suivre tous les messages entrants
    tail -f tracker.events | jq
    ```

3.  **Arr√™ter l'environnement :**
    ```bash
    ./stop.sh
    ```
    Ce script arr√™te proprement les applications Go, puis les conteneurs Docker.

## Observabilit√© et Journalisation

Le syst√®me utilise une strat√©gie de journalisation √† deux fichiers pour s√©parer les pr√©occupations :

1.  **`tracker.log` : Journal d'Observabilit√© Syst√®me**
    -   **Quoi ?** √âv√©nements de cycle de vie (d√©marrage, arr√™t), m√©triques p√©riodiques, et erreurs critiques.
    -   **Pourquoi ?** Pour le **monitoring** et l'**alerte**. Ce fichier est concis et contient les indicateurs de sant√© du syst√®me.
    -   **Format** : JSON structur√©.

2.  **`tracker.events` : Journal de Tra√ßabilit√© des Messages**
    -   **Quoi ?** Une copie de **chaque message** re√ßu de Kafka, qu'il soit valide ou non.
    -   **Pourquoi ?** Pour l'**audit**, le **d√©bogage** et la **relecture** d'√©v√©nements. Il garantit qu'aucune donn√©e entrante n'est perdue.
    -   **Format** : JSON, avec le message brut, les m√©tadonn√©es Kafka et le r√©sultat de la d√©s√©rialisation.

### Analyse des Journaux

Un script est fourni pour une analyse rapide. Rendez-le ex√©cutable et lancez-le :

```bash
chmod +x analyze_logs.sh
./analyze_logs.sh
```

#### Exemples d'Analyse avec `jq`

`jq` est un outil puissant pour exploiter les journaux JSON.

-   **Voir les erreurs syst√®me :**
    ```bash
    jq 'select(.level == "ERROR")' tracker.log
    ```

-   **Reconstruire l'historique d'une commande (depuis `tracker.events`) :**
    ```bash
    jq 'select(.deserialized == true and .order_full.order_id == "VOTRE_ID")' tracker.events
    ```

-   **Compter les messages par statut de commande :**
    ```bash
    jq -r 'select(.deserialized == true) | .order_full.status' tracker.events | sort | uniq -c
    ```

-   **Suivre l'√©volution du d√©bit de messages (depuis `tracker.log`) :**
    ```bash
    jq -r 'select(.message == "M√©triques syst√®me p√©riodiques") | [.timestamp, .metadata.messages_per_second] | @csv' tracker.log
    ```

## Structure du Code

-   **`order.go`** : D√©finit le mod√®le de donn√©es partag√© (`Order`, `CustomerInfo`, etc.) utilis√© par le producteur et le consommateur.
-   **`producer.go`** : Le code source du producteur.
-   **`tracker.go`** : Le code source du consommateur.
-   **`docker-compose.yaml`** : D√©finit le service Kafka.
-   **`start.sh` / `stop.sh`** : Scripts pour g√©rer le cycle de vie de l'application.
-   **`analyze_logs.sh`** : Script pour l'analyse des journaux.
-   **`go.mod` / `go.sum`** : Fichiers de d√©pendances Go.

## Commandes Kafka Utiles

-   **Lister les topics :**
    ```bash
    docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list
    ```

-   **Consommer les messages depuis le terminal (pour le d√©bogage) :**
    ```bash
    docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic orders --from-beginning
    ```
