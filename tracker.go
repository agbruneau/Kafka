/*
Ce programme Go, `tracker.go`, est un consommateur de messages pour Apache Kafka.
Il est con√ßu pour suivre les messages d'un topic Kafka sp√©cifi√©, les d√©s√©rialiser
et afficher les informations qu'ils contiennent.

Le programme est configur√© pour se connecter √† un serveur Kafka fonctionnant sur `localhost:9092`
et s'abonner au topic `orders`. Il √©coute en continu les nouveaux messages et les
affiche dans la console.

Fonctionnalit√©s:
- Configuration et initialisation d'un consommateur Kafka.
- Abonnement √† un topic Kafka.
- Boucle de consommation pour recevoir et traiter les messages en temps r√©el.
- Gestion des erreurs et fermeture propre du consommateur.
*/

package main

import (
	"encoding/json"
	"fmt"
	"log"
	"os"
	"os/signal"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/confluentinc/confluent-kafka-go/v2/kafka"
)

// LogLevel repr√©sente les niveaux de log disponibles
type LogLevel string

const (
	LogLevelDEBUG LogLevel = "DEBUG"
	LogLevelINFO  LogLevel = "INFO"
	LogLevelWARN  LogLevel = "WARN"
	LogLevelERROR LogLevel = "ERROR"
)

// LogEntry repr√©sente une entr√©e de log structur√©e
type LogEntry struct {
	Timestamp     string                 `json:"timestamp"`
	Level         LogLevel               `json:"level"`
	Message       string                 `json:"message"`
	Service       string                 `json:"service"`
	OrderID       string                 `json:"order_id,omitempty"`
	Sequence      int                    `json:"sequence,omitempty"`
	Error         string                 `json:"error,omitempty"`
	Metadata      map[string]interface{} `json:"metadata,omitempty"`
	EventType     string                 `json:"event_type,omitempty"`
	CorrelationID string                 `json:"correlation_id,omitempty"`
}

// Logger g√®re l'√©criture des logs dans un fichier
type Logger struct {
	file    *os.File
	encoder *json.Encoder
	mu      sync.Mutex
}

var globalLogger *Logger
var eventLogger *Logger
var instanceID string // Identifiant unique de cette instance pour la scalabilit√© horizontale

// SystemMetrics repr√©sente les m√©triques syst√®me pour l'observabilit√©
type SystemMetrics struct {
	StartTime           time.Time
	MessagesReceived    int64
	MessagesProcessed   int64
	MessagesFailed      int64
	LastMessageTime     time.Time
	LastProcessedOffset int64
	mu                  sync.RWMutex
}

var systemMetrics = &SystemMetrics{
	StartTime: time.Now(),
}

// EventEntry repr√©sente une entr√©e d'√©v√©nement (message re√ßu)
type EventEntry struct {
	Timestamp      string          `json:"timestamp"`
	EventType      string          `json:"event_type"`
	KafkaTopic     string          `json:"kafka_topic,omitempty"`
	KafkaPartition int32           `json:"kafka_partition,omitempty"`
	KafkaOffset    int64           `json:"kafka_offset,omitempty"`
	KafkaKey       string          `json:"kafka_key,omitempty"`
	RawMessage     string          `json:"raw_message"`
	MessageSize    int             `json:"message_size"`
	OrderID        string          `json:"order_id,omitempty"`
	Sequence       int             `json:"sequence,omitempty"`
	Status         string          `json:"status,omitempty"`
	Deserialized   bool            `json:"deserialized"`
	Error          string          `json:"error,omitempty"`
	OrderFull      json.RawMessage `json:"order_full,omitempty"`
}

// initLogger initialise le syst√®me de logging
func initLogger() error {
	// R√©cup√©rer l'identifiant d'instance depuis la variable d'environnement
	instanceID = os.Getenv("TRACKER_INSTANCE_ID")
	if instanceID == "" {
		// G√©n√©rer un ID bas√© sur le PID si non fourni
		instanceID = fmt.Sprintf("instance-%d", os.Getpid())
	}

	// Utiliser des fichiers de logs avec l'ID d'instance pour √©viter les conflits
	logFileName := fmt.Sprintf("tracker-%s.log", instanceID)
	eventFileName := fmt.Sprintf("tracker-%s.events", instanceID)

	// Initialiser le logger pour les logs d'observabilit√©
	logFile, err := os.OpenFile(logFileName, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
	if err != nil {
		return fmt.Errorf("impossible d'ouvrir le fichier de log: %v", err)
	}

	globalLogger = &Logger{
		file:    logFile,
		encoder: json.NewEncoder(logFile),
	}

	// Initialiser le logger pour les √©v√©nements (journalisation compl√®te)
	eventFile, err := os.OpenFile(eventFileName, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
	if err != nil {
		return fmt.Errorf("impossible d'ouvrir le fichier d'√©v√©nements: %v", err)
	}

	eventLogger = &Logger{
		file:    eventFile,
		encoder: json.NewEncoder(eventFile),
	}

	// V√©rifier que le fichier a bien √©t√© cr√©√©
	if eventLogger.file == nil {
		return fmt.Errorf("impossible d'initialiser le fichier d'√©v√©nements")
	}

	// Log de d√©marrage du syst√®me avec informations d'observabilit√©
	globalLogger.Log(LogLevelINFO, "Syst√®me de journalisation initialis√©", map[string]interface{}{
		"instance_id": instanceID,
		"log_file":    logFileName,
		"events_file": eventFileName,
		"start_time":  time.Now().UTC().Format(time.RFC3339),
	})

	// Journaliser un √©v√©nement de d√©marrage dans tracker.events pour v√©rifier que √ßa fonctionne
	// (Cet √©v√©nement confirme que le syst√®me de journalisation des √©v√©nements est op√©rationnel)

	return nil
}

// IncrementMessagesReceived incr√©mente le compteur de messages re√ßus
func (sm *SystemMetrics) IncrementMessagesReceived() {
	sm.mu.Lock()
	defer sm.mu.Unlock()
	sm.MessagesReceived++
	sm.LastMessageTime = time.Now()
}

// IncrementMessagesProcessed incr√©mente le compteur de messages trait√©s avec succ√®s
func (sm *SystemMetrics) IncrementMessagesProcessed(offset int64) {
	sm.mu.Lock()
	defer sm.mu.Unlock()
	sm.MessagesProcessed++
	sm.LastProcessedOffset = offset
}

// IncrementMessagesFailed incr√©mente le compteur de messages en √©chec
func (sm *SystemMetrics) IncrementMessagesFailed() {
	sm.mu.Lock()
	defer sm.mu.Unlock()
	sm.MessagesFailed++
}

// GetMetrics retourne une copie des m√©triques actuelles
func (sm *SystemMetrics) GetMetrics() SystemMetrics {
	sm.mu.RLock()
	defer sm.mu.RUnlock()
	return SystemMetrics{
		StartTime:           sm.StartTime,
		MessagesReceived:    sm.MessagesReceived,
		MessagesProcessed:   sm.MessagesProcessed,
		MessagesFailed:      sm.MessagesFailed,
		LastMessageTime:     sm.LastMessageTime,
		LastProcessedOffset: sm.LastProcessedOffset,
	}
}

// Log √©crit une entr√©e de log structur√©e
func (l *Logger) Log(level LogLevel, message string, metadata map[string]interface{}) {
	l.mu.Lock()
	defer l.mu.Unlock()

	entry := LogEntry{
		Timestamp: time.Now().UTC().Format(time.RFC3339),
		Level:     level,
		Message:   message,
		Service:   "order-tracker",
		Metadata:  metadata,
	}
	// Ajouter l'instance ID aux m√©tadonn√©es si disponible
	if instanceID != "" {
		if entry.Metadata == nil {
			entry.Metadata = make(map[string]interface{})
		}
		entry.Metadata["instance_id"] = instanceID
	}

	if err := l.encoder.Encode(entry); err != nil {
		log.Printf("Erreur lors de l'√©criture du log: %v", err)
	}

	// Flush pour s'assurer que les logs sont √©crits imm√©diatement
	l.file.Sync()
}

// LogOrder √©crit un log sp√©cifique pour une commande avec le contenu complet du message
func (l *Logger) LogOrder(level LogLevel, message string, order Order, kafkaMsg *kafka.Message) {
	l.mu.Lock()
	defer l.mu.Unlock()

	// S√©rialiser la structure Order compl√®te en JSON pour journalisation
	orderJSON, err := json.Marshal(order)
	if err != nil {
		log.Printf("Erreur lors de la s√©rialisation de la commande: %v", err)
		orderJSON = []byte("{}")
	}

	// Pr√©parer les m√©tadonn√©es Kafka
	kafkaMetadata := make(map[string]interface{})
	if kafkaMsg != nil {
		if kafkaMsg.TopicPartition.Topic != nil {
			kafkaMetadata["kafka_topic"] = *kafkaMsg.TopicPartition.Topic
		}
		kafkaMetadata["kafka_partition"] = kafkaMsg.TopicPartition.Partition
		kafkaMetadata["kafka_offset"] = kafkaMsg.TopicPartition.Offset
		if kafkaMsg.Key != nil {
			kafkaMetadata["kafka_key"] = string(kafkaMsg.Key)
		}
		// Le timestamp Kafka est disponible via les headers ou peut √™tre omis
		if !kafkaMsg.Timestamp.IsZero() {
			kafkaMetadata["kafka_timestamp"] = kafkaMsg.Timestamp.Format(time.RFC3339)
		}
	}

	// Pr√©parer les m√©tadonn√©es compl√®tes incluant le message brut et la structure compl√®te
	metadata := map[string]interface{}{
		"status":           order.Status,
		"total":            order.Total,
		"currency":         order.Currency,
		"customer_id":      order.CustomerInfo.CustomerID,
		"customer_name":    order.CustomerInfo.Name,
		"items_count":      len(order.Items),
		"payment_method":   order.PaymentMethod,
		"items":            order.Items,
		"inventory_status": order.InventoryStatus,
		// Ajout de la structure Order compl√®te s√©rialis√©e en JSON
		"order_full": json.RawMessage(orderJSON),
		// M√©tadonn√©es Kafka
		"kafka": kafkaMetadata,
	}

	// Ajout du message brut re√ßu de Kafka (pour tra√ßabilit√© compl√®te)
	if kafkaMsg != nil && kafkaMsg.Value != nil {
		metadata["raw_message"] = string(kafkaMsg.Value)
	}

	entry := LogEntry{
		Timestamp:     time.Now().UTC().Format(time.RFC3339),
		Level:         level,
		Message:       message,
		Service:       "order-tracker",
		OrderID:       order.OrderID,
		Sequence:      order.Sequence,
		EventType:     order.Metadata.EventType,
		CorrelationID: order.Metadata.CorrelationID,
		Metadata:      metadata,
	}

	if err := l.encoder.Encode(entry); err != nil {
		log.Printf("Erreur lors de l'√©criture du log: %v", err)
	}

	l.file.Sync()
}

// LogError √©crit un log d'erreur
func (l *Logger) LogError(message string, err error, metadata map[string]interface{}) {
	if metadata == nil {
		metadata = make(map[string]interface{})
	}
	metadata["error"] = err.Error()
	l.Log(LogLevelERROR, message, metadata)
}

// LogRawMessage √©crit un log pour un message brut re√ßu de Kafka (m√™me en cas d'erreur de d√©s√©rialisation)
func (l *Logger) LogRawMessage(level LogLevel, message string, kafkaMsg *kafka.Message, deserializationError error) {
	l.mu.Lock()
	defer l.mu.Unlock()

	// Pr√©parer les m√©tadonn√©es Kafka
	kafkaMetadata := make(map[string]interface{})
	if kafkaMsg != nil {
		if kafkaMsg.TopicPartition.Topic != nil {
			kafkaMetadata["kafka_topic"] = *kafkaMsg.TopicPartition.Topic
		}
		kafkaMetadata["kafka_partition"] = kafkaMsg.TopicPartition.Partition
		kafkaMetadata["kafka_offset"] = kafkaMsg.TopicPartition.Offset
		if kafkaMsg.Key != nil {
			kafkaMetadata["kafka_key"] = string(kafkaMsg.Key)
		}
		if !kafkaMsg.Timestamp.IsZero() {
			kafkaMetadata["kafka_timestamp"] = kafkaMsg.Timestamp.Format(time.RFC3339)
		}
	}

	metadata := map[string]interface{}{
		"kafka": kafkaMetadata,
	}

	// Ajouter le message brut
	if kafkaMsg != nil && kafkaMsg.Value != nil {
		metadata["raw_message"] = string(kafkaMsg.Value)
		metadata["raw_message_size"] = len(kafkaMsg.Value)
	}

	// Ajouter l'erreur de d√©s√©rialisation si pr√©sente
	if deserializationError != nil {
		metadata["deserialization_error"] = deserializationError.Error()
	}

	entry := LogEntry{
		Timestamp: time.Now().UTC().Format(time.RFC3339),
		Level:     level,
		Message:   message,
		Service:   "order-tracker",
		Metadata:  metadata,
	}

	if deserializationError != nil {
		entry.Error = deserializationError.Error()
	}

	if err := l.encoder.Encode(entry); err != nil {
		log.Printf("Erreur lors de l'√©criture du log: %v", err)
	}

	l.file.Sync()
}

// Close ferme le fichier de log
func (l *Logger) Close() error {
	l.mu.Lock()
	defer l.mu.Unlock()
	return l.file.Close()
}

// LogEvent journalise un √©v√©nement (message re√ßu) dans tracker.events
func (l *Logger) LogEvent(kafkaMsg *kafka.Message, order *Order, deserializationError error) {
	if l == nil {
		log.Printf("ERREUR: eventLogger est nil - impossible de journaliser l'√©v√©nement")
		return
	}

	l.mu.Lock()
	defer l.mu.Unlock()

	if l.file == nil {
		log.Printf("ERREUR: fichier d'√©v√©nements non initialis√©")
		return
	}

	event := EventEntry{
		Timestamp:    time.Now().UTC().Format(time.RFC3339),
		EventType:    "message.received",
		Deserialized: order != nil,
	}

	// M√©tadonn√©es Kafka
	if kafkaMsg != nil {
		if kafkaMsg.TopicPartition.Topic != nil {
			event.KafkaTopic = *kafkaMsg.TopicPartition.Topic
		}
		event.KafkaPartition = kafkaMsg.TopicPartition.Partition
		event.KafkaOffset = int64(kafkaMsg.TopicPartition.Offset)
		if kafkaMsg.Key != nil {
			event.KafkaKey = string(kafkaMsg.Key)
		}
		if kafkaMsg.Value != nil {
			event.RawMessage = string(kafkaMsg.Value)
			event.MessageSize = len(kafkaMsg.Value)
		} else {
			// Si kafkaMsg existe mais Value est nil, initialiser avec cha√Æne vide
			event.RawMessage = ""
			event.MessageSize = 0
		}
	} else {
		// Si kafkaMsg est nil (√©v√©nement syst√®me), initialiser avec cha√Æne vide
		event.RawMessage = ""
		event.MessageSize = 0
		event.EventType = "system.startup"
	}

	// Informations de la commande si d√©s√©rialis√©e avec succ√®s
	if order != nil {
		event.OrderID = order.OrderID
		event.Sequence = order.Sequence
		event.Status = order.Status
		// S√©rialiser la structure Order compl√®te
		orderJSON, err := json.Marshal(order)
		if err == nil {
			event.OrderFull = json.RawMessage(orderJSON)
		}
	}

	// Erreur de d√©s√©rialisation si pr√©sente
	if deserializationError != nil {
		event.Error = deserializationError.Error()
		event.EventType = "message.received.deserialization_error"
	}

	// Encoder et √©crire l'√©v√©nement
	if err := l.encoder.Encode(event); err != nil {
		log.Printf("ERREUR lors de l'√©criture de l'√©v√©nement dans tracker.events: %v", err)
		return
	}

	// S'assurer que les donn√©es sont √©crites sur le disque
	if err := l.file.Sync(); err != nil {
		log.Printf("ERREUR lors du flush du fichier tracker.events: %v", err)
	}
}

// main initialise et ex√©cute le consommateur Kafka.
// Il configure le consommateur pour se connecter au broker Kafka,
// s'abonne au topic 'orders', et entre dans une boucle de scrutation
// pour recevoir et traiter les messages. La fonction g√®re √©galement
// les signaux d'arr√™t pour une fermeture propre.
func main() {
	// Initialisation du syst√®me de logging
	if err := initLogger(); err != nil {
		fmt.Printf("‚ùå Erreur lors de l'initialisation du logging: %v\n", err)
		os.Exit(1)
	}
	defer globalLogger.Close()
	defer eventLogger.Close()

	// Configuration du consommateur
	consumerConfig := kafka.ConfigMap{
		"bootstrap.servers": "localhost:9092",
		"group.id":          "order-tracker",
		"auto.offset.reset": "earliest",
	}

	// Cr√©ation du consommateur
	consumer, err := kafka.NewConsumer(&consumerConfig)
	if err != nil {
		globalLogger.LogError("Erreur lors de la cr√©ation du consommateur", err, map[string]interface{}{
			"bootstrap_servers": "localhost:9092",
			"group_id":          "order-tracker",
		})
		fmt.Printf("Erreur lors de la cr√©ation du consommateur: %v\n", err)
		os.Exit(1)
	}
	defer consumer.Close()

	// Abonnement au topic
	err = consumer.SubscribeTopics([]string{"orders"}, nil)
	if err != nil {
		globalLogger.LogError("Erreur lors de l'abonnement au topic", err, map[string]interface{}{
			"topic": "orders",
		})
		fmt.Printf("Erreur lors de l'abonnement au topic: %v\n", err)
		os.Exit(1)
	}

	// Log d'initialisation du consommateur avec informations syst√®me
	globalLogger.Log(LogLevelINFO, "Consommateur Kafka initialis√©", map[string]interface{}{
		"instance_id":       instanceID,
		"topic":             "orders",
		"group_id":          "order-tracker",
		"bootstrap_server":  "localhost:9092",
		"mode":              "Event Carried State Transfer (ECST)",
		"pattern":           "Competing Consumers (scalabilit√© horizontale)",
		"auto_offset_reset": "earliest",
		"start_time":        time.Now().UTC().Format(time.RFC3339),
	})

	fmt.Printf("üü¢ Instance %s: Le consommateur est en cours d'ex√©cution et abonn√© au topic 'orders'\n", instanceID)
	fmt.Println("üì° Mode: Event Carried State Transfer (ECST) - √âtat complet dans chaque message")
	fmt.Printf("üîÑ Pattern: Competing Consumers (scalabilit√© horizontale) - Instance %s\n", instanceID)
	fmt.Printf("üìù Les logs d'observabilit√© syst√®me sont enregistr√©s dans tracker-%s.log\n", instanceID)
	fmt.Printf("üìã La journalisation compl√®te des √©v√©nements est dans tracker-%s.events\n", instanceID)

	// V√©rification que eventLogger est bien initialis√©
	if eventLogger == nil {
		fmt.Println("‚ö†Ô∏è  ATTENTION: eventLogger n'est pas initialis√© - les √©v√©nements ne seront pas journalis√©s!")
	} else if eventLogger.file == nil {
		fmt.Println("‚ö†Ô∏è  ATTENTION: fichier tracker.events non initialis√© - les √©v√©nements ne seront pas journalis√©s!")
	} else {
		fmt.Println("‚úÖ Syst√®me de journalisation des √©v√©nements op√©rationnel")
	}

	// Gestion de l'interruption propre (Ctrl+C)
	sigchan := make(chan os.Signal, 1)
	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)

	// Ticker pour les m√©triques p√©riodiques (toutes les 30 secondes)
	metricsTicker := time.NewTicker(30 * time.Second)
	defer metricsTicker.Stop()

	// Goroutine pour logger les m√©triques p√©riodiques
	go func() {
		for range metricsTicker.C {
			metrics := systemMetrics.GetMetrics()
			uptime := time.Since(metrics.StartTime)

			// Calculer les taux
			var successRate float64
			if metrics.MessagesReceived > 0 {
				successRate = float64(metrics.MessagesProcessed) / float64(metrics.MessagesReceived) * 100
			}

			var messagesPerSecond float64
			if uptime.Seconds() > 0 {
				messagesPerSecond = float64(metrics.MessagesReceived) / uptime.Seconds()
			}

			globalLogger.Log(LogLevelINFO, "M√©triques syst√®me", map[string]interface{}{
				"instance_id":           instanceID,
				"uptime_seconds":        int64(uptime.Seconds()),
				"messages_received":     metrics.MessagesReceived,
				"messages_processed":    metrics.MessagesProcessed,
				"messages_failed":       metrics.MessagesFailed,
				"success_rate_percent":  fmt.Sprintf("%.2f", successRate),
				"messages_per_second":   fmt.Sprintf("%.2f", messagesPerSecond),
				"last_message_time":     metrics.LastMessageTime.Format(time.RFC3339),
				"last_processed_offset": metrics.LastProcessedOffset,
			})
		}
	}()

	// Boucle de consommation
	run := true
	shutdownRequested := false
	var shutdownTime time.Time

	for run {
		select {
		case <-sigchan:
			// Signal d'arr√™t re√ßu - continuer √† traiter les messages en cours
			if !shutdownRequested {
				shutdownRequested = true
				shutdownTime = time.Now()

				globalLogger.Log(LogLevelINFO, "Signal d'arr√™t re√ßu - traitement des messages en cours", map[string]interface{}{
					"instance_id": instanceID,
					"signal":      "SIGINT/SIGTERM",
				})

				fmt.Println("\n‚ö†Ô∏è  Signal d'arr√™t re√ßu - traitement des messages en cours...")
				fmt.Println("   (Les messages en attente seront trait√©s avant l'arr√™t)")
			}
		default:
			// Si l'arr√™t est demand√© et qu'on n'a pas re√ßu de message depuis 5 secondes, arr√™ter
			if shutdownRequested {
				timeSinceShutdown := time.Since(shutdownTime)
				if timeSinceShutdown > 5*time.Second {
					// Aucun message re√ßu depuis 5 secondes apr√®s le signal - arr√™ter proprement
					run = false
					break
				}
			}

			// Poll pour recevoir des messages (timeout de 1 seconde)
			msg, err := consumer.ReadMessage(1000 * time.Millisecond)
			if err != nil {
				// Timeout ou erreur temporaire
				kafkaErr, ok := err.(kafka.Error)
				if ok && kafkaErr.Code() == kafka.ErrTimedOut {
					// Si l'arr√™t est demand√© et qu'on a un timeout, v√©rifier si on doit arr√™ter
					if shutdownRequested {
						timeSinceShutdown := time.Since(shutdownTime)
						// Si on a attendu 3 secondes sans message apr√®s le signal, arr√™ter
						if timeSinceShutdown > 3*time.Second {
							run = false
							break
						}
					}
					continue
				}
				// Log de l'erreur (msg peut √™tre nil en cas d'erreur)
				metadata := make(map[string]interface{})
				if msg != nil {
					metadata["topic"] = msg.TopicPartition.Topic
					metadata["partition"] = msg.TopicPartition.Partition
				}
				globalLogger.LogError("Erreur lors de la lecture du message Kafka", err, metadata)
				fmt.Printf("‚ùå Erreur: %v\n", err)
				continue
			}

			// IMPORTANT: Journaliser TOUS les messages re√ßus dans tracker.events
			// pour une tra√ßabilit√© compl√®te, ind√©pendamment du succ√®s de la d√©s√©rialisation

			// D√©s√©rialisation du message
			var order *Order
			var deserializationErr error
			var tempOrder Order

			deserializationErr = json.Unmarshal(msg.Value, &tempOrder)
			if deserializationErr == nil {
				order = &tempOrder
			}

			// Mettre √† jour les m√©triques
			systemMetrics.IncrementMessagesReceived()

			// Journaliser l'√©v√©nement dans tracker.events (toujours, m√™me en cas d'erreur)
			if eventLogger != nil {
				eventLogger.LogEvent(msg, order, deserializationErr)
			} else {
				log.Printf("ERREUR CRITIQUE: eventLogger est nil - impossible de journaliser l'√©v√©nement")
			}

			// tracker.log contient les erreurs ET les m√©triques d'observabilit√©
			if deserializationErr != nil {
				// Mettre √† jour les m√©triques d'√©chec
				systemMetrics.IncrementMessagesFailed()

				// Logger l'erreur dans tracker.log
				globalLogger.LogRawMessage(LogLevelERROR, "Erreur lors de la d√©s√©rialisation du message", msg, deserializationErr)
				fmt.Printf("Erreur lors de la d√©s√©rialisation: %v\n", deserializationErr)
				continue
			}

			// Mettre √† jour les m√©triques de succ√®s
			if msg != nil {
				systemMetrics.IncrementMessagesProcessed(int64(msg.TopicPartition.Offset))
				// Si on est en mode shutdown et qu'on a trait√© un message, r√©initialiser le timer
				if shutdownRequested {
					shutdownTime = time.Now()
				}
			}

			// Affichage enrichi de la commande avec l'√©tat complet (Event Carried State Transfer)
			fmt.Println("\n" + strings.Repeat("=", 80))
			fmt.Printf("üì¶ COMMANDE #%d - √âtat complet re√ßu (ECST)\n", order.Sequence)
			fmt.Println(strings.Repeat("-", 80))

			// Informations de base
			fmt.Printf("üÜî ID Commande: %s\n", order.OrderID)
			fmt.Printf("üìä Statut: %s\n", order.Status)
			fmt.Printf("üïê Timestamp: %s\n", order.Metadata.Timestamp)
			fmt.Printf("üìå Version: %s | Type: %s | Source: %s\n", order.Metadata.Version, order.Metadata.EventType, order.Metadata.Source)
			fmt.Printf("üîó Correlation ID: %s\n", order.Metadata.CorrelationID)

			// Informations client
			fmt.Println("\nüë§ INFORMATIONS CLIENT:")
			fmt.Printf("   ‚Ä¢ ID: %s | Nom: %s\n", order.CustomerInfo.CustomerID, order.CustomerInfo.Name)
			fmt.Printf("   ‚Ä¢ Email: %s | T√©l√©phone: %s\n", order.CustomerInfo.Email, order.CustomerInfo.Phone)
			fmt.Printf("   ‚Ä¢ Adresse: %s\n", order.CustomerInfo.Address)
			fmt.Printf("   ‚Ä¢ Niveau de fid√©lit√©: %s\n", order.CustomerInfo.LoyaltyLevel)

			// Articles command√©s
			fmt.Println("\nüõí ARTICLES COMMAND√âS:")
			for i, item := range order.Items {
				fmt.Printf("   %d. %s (ID: %s)\n", i+1, item.ItemName, item.ItemID)
				fmt.Printf("      Quantit√©: %d | Prix unitaire: %.2f %s | Total: %.2f %s\n",
					item.Quantity, item.UnitPrice, order.Currency, item.TotalPrice, order.Currency)
			}

			// Statut de l'inventaire
			fmt.Println("\nüì¶ STATUT DE L'INVENTAIRE:")
			for i, inv := range order.InventoryStatus {
				stockStatus := "‚úÖ En stock"
				if !inv.InStock {
					stockStatus = "‚ùå Rupture de stock"
				}
				fmt.Printf("   %d. %s (ID: %s)\n", i+1, inv.ItemName, inv.ItemID)
				fmt.Printf("      %s | Disponible: %d | R√©serv√©: %d | Entrep√¥t: %s\n",
					stockStatus, inv.AvailableQty, inv.ReservedQty, inv.Warehouse)
			}

			// D√©tails financiers
			fmt.Println("\nüí∞ D√âTAILS FINANCIERS:")
			fmt.Printf("   ‚Ä¢ Sous-total: %.2f %s\n", order.SubTotal, order.Currency)
			fmt.Printf("   ‚Ä¢ Taxes (TVA): %.2f %s\n", order.Tax, order.Currency)
			fmt.Printf("   ‚Ä¢ Frais de livraison: %.2f %s\n", order.ShippingFee, order.Currency)
			fmt.Printf("   ‚Ä¢ TOTAL: %.2f %s\n", order.Total, order.Currency)
			fmt.Printf("   ‚Ä¢ M√©thode de paiement: %s\n", order.PaymentMethod)
			fmt.Printf("   ‚Ä¢ Adresse de livraison: %s\n", order.ShippingAddress)

			fmt.Println(strings.Repeat("=", 80))
		}
	}

	// Log de fermeture propre avec statistiques finales
	metrics := systemMetrics.GetMetrics()
	uptime := time.Since(metrics.StartTime)

	var successRate float64
	if metrics.MessagesReceived > 0 {
		successRate = float64(metrics.MessagesProcessed) / float64(metrics.MessagesReceived) * 100
	}

	shutdownDuration := time.Duration(0)
	if shutdownRequested {
		shutdownDuration = time.Since(shutdownTime)
	}

	globalLogger.Log(LogLevelINFO, "Consommateur arr√™t√© proprement", map[string]interface{}{
		"instance_id":                instanceID,
		"uptime_seconds":             int64(uptime.Seconds()),
		"total_messages_received":    metrics.MessagesReceived,
		"total_messages_processed":   metrics.MessagesProcessed,
		"total_messages_failed":      metrics.MessagesFailed,
		"final_success_rate_percent": fmt.Sprintf("%.2f", successRate),
		"shutdown_duration_seconds":  int64(shutdownDuration.Seconds()),
		"shutdown_time":              time.Now().UTC().Format(time.RFC3339),
	})

	fmt.Println("‚úÖ Tous les messages en cours ont √©t√© trait√©s")
}
