package main

import (
	"fmt"
	"log"
	"os"
	"os/signal"
	"strings"
	"syscall"
	"time"

	"github.com/confluentinc/confluent-kafka-go/v2/kafka"
)

func main() {
	if err := initLoggers(); err != nil {
		log.Fatalf("Erreur fatale lors de l'initialisation des loggers: %v", err)
	}
	defer logLogger.Close()
	defer eventLogger.Close()

	consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
		"bootstrap.servers": "localhost:9092",
		"group.id":          "order-tracker-group",
		"auto.offset.reset": "earliest",
	})
	if err != nil {
		logLogger.LogError("Erreur lors de la crÃ©ation du consommateur", err, nil)
		log.Fatalf("Erreur fatale: %v", err)
	}
	defer consumer.Close()

	err = consumer.SubscribeTopics([]string{"orders"}, nil)
	if err != nil {
		logLogger.LogError("Erreur lors de l'abonnement au topic", err, map[string]interface{}{"topic": "orders"})
		log.Fatalf("Erreur fatale: %v", err)
	}

	logLogger.Log(LogLevelINFO, "Consommateur dÃ©marrÃ© et abonnÃ© au topic 'orders'", nil)
	fmt.Println("ğŸŸ¢ Le consommateur est en cours d'exÃ©cution...")
	fmt.Println("ğŸ“ Logs d'observabilitÃ© systÃ¨me dans tracker.log")
	fmt.Println("ğŸ“‹ Journalisation complÃ¨te des messages dans tracker.events")

	// Canal pour arrÃªter proprement la goroutine de mÃ©triques
	metricsStopChan := make(chan struct{})
	go logPeriodicMetrics(metricsStopChan)

	sigchan := make(chan os.Signal, 1)
	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)

	run := true
	consecutiveErrors := 0
	maxConsecutiveErrors := 3 // ArrÃªter aprÃ¨s 3 erreurs consÃ©cutives (probablement Kafka arrÃªtÃ©)

	for run {
		select {
		case <-sigchan:
			logLogger.Log(LogLevelINFO, "Signal d'arrÃªt reÃ§u, fin de la consommation.", nil)
			run = false
		default:
			msg, err := consumer.ReadMessage(1 * time.Second)
			if err != nil {
				if err.(kafka.Error).Code() == kafka.ErrTimedOut {
					consecutiveErrors = 0 // RÃ©initialiser le compteur si c'est juste un timeout
					continue              // Pas de message, c'est normal.
				}

				// VÃ©rifier si c'est une erreur de connexion critique (brokers down)
				kafkaErr, ok := err.(kafka.Error)
				isShutdownError := false
				if ok {
					errorMsg := err.Error()
					if strings.Contains(errorMsg, "brokers are down") ||
						strings.Contains(errorMsg, "Connection refused") ||
						kafkaErr.Code() == kafka.ErrAllBrokersDown {
						isShutdownError = true
						consecutiveErrors++
						if consecutiveErrors >= maxConsecutiveErrors {
							// Logger comme INFO au lieu d'ERROR car c'est un arrÃªt normal
							logLogger.Log(LogLevelINFO, "Kafka semble Ãªtre arrÃªtÃ©, arrÃªt du consommateur", map[string]interface{}{
								"consecutive_errors": consecutiveErrors,
								"reason":             "brokers_unavailable",
							})
							run = false
							break
						}
						// Ne pas logger les erreurs intermÃ©diaires de shutdown pour Ã©viter le bruit
						continue
					}
				}

				// Logger seulement les erreurs qui ne sont pas liÃ©es Ã  l'arrÃªt
				if !isShutdownError {
					logLogger.LogError("Erreur de lecture du message Kafka", err, nil)
					consecutiveErrors++
					if consecutiveErrors >= maxConsecutiveErrors {
						logLogger.LogError("Trop d'erreurs consÃ©cutives, arrÃªt du consommateur", err, map[string]interface{}{
							"consecutive_errors": consecutiveErrors,
						})
						run = false
						break
					}
				}
				continue
			}

			// RÃ©initialiser le compteur d'erreurs en cas de succÃ¨s
			consecutiveErrors = 0
			processMessage(msg)
		}
	}

	// ArrÃªter la goroutine de mÃ©triques avant de quitter
	close(metricsStopChan)

	// Log final avant de quitter
	uptime := time.Since(systemMetrics.StartTime)
	logLogger.Log(LogLevelINFO, "Consommateur arrÃªtÃ© proprement", map[string]interface{}{
		"uptime_seconds":           uptime.Seconds(),
		"total_messages_received":  systemMetrics.MessagesReceived,
		"total_messages_processed": systemMetrics.MessagesProcessed,
		"total_messages_failed":    systemMetrics.MessagesFailed,
	})
	fmt.Println("\nğŸ”´ Le consommateur est arrÃªtÃ©.")
}
