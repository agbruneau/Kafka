/*
Ce programme Go (`tracker.go`) est un consommateur de messages pour Apache Kafka.
Son r√¥le principal est de s'abonner au topic 'orders', de recevoir les messages,
de les traiter et de maintenir une observabilit√© compl√®te du syst√®me.

Il met en ≈ìuvre plusieurs patrons d'architecture et bonnes pratiques essentiels :
- **Consommation de messages** : Il se connecte √† Kafka et √©coute en continu les nouveaux messages,
  suivant le mod√®le Publisher/Subscriber.
- **D√©s√©rialisation** : Il transforme les messages JSON entrants en structures Go (`Order`).
- **Observabilit√© avanc√©e** : Il utilise une strat√©gie de logging √† deux fichiers qui impl√©mente
  deux patrons distincts :
  1. **Application Health Monitoring** (`tracker.log`): Pour les logs syst√®me structur√©s
     (d√©marrage, arr√™t, erreurs, m√©triques). Ce fichier est optimis√© pour le monitoring,
     les dashboards et l'alerte.
  2. **Audit Trail** (`tracker.events`): Pour la journalisation exhaustive de chaque
     message re√ßu. Ce fichier garantit une tra√ßabilit√© compl√®te et sert de source de v√©rit√©
     immuable pour les donn√©es entrantes.
- **M√©triques syst√®me** : Il collecte et affiche p√©riodiquement des m√©triques de performance
  (d√©bit, taux de succ√®s, etc.) pour √©valuer la sant√© du service.
- **Graceful Shutdown** : Il g√®re les signaux d'arr√™t (Ctrl+C) pour s'assurer que les messages
  en cours de traitement ne sont pas perdus et que les ressources sont correctement lib√©r√©es.
*/

package main

import (
	"encoding/json"
	"fmt"
	"os"
	"strings"
	"sync"
	"time"

	"github.com/confluentinc/confluent-kafka-go/v2/kafka"
)

// LogLevel d√©finit les niveaux de s√©v√©rit√© pour les logs structur√©s.
type LogLevel string

const (
	LogLevelINFO  LogLevel = "INFO"
	LogLevelERROR LogLevel = "ERROR"
)

// LogEntry est la structure d'un log √©crit dans `tracker.log`.
// Elle est con√ßue pour le patron "Application Health Monitoring".
// Chaque entr√©e est un log structur√© (JSON) contenant des informations sur l'√©tat
// de l'application (d√©marrage, arr√™t, erreurs, m√©triques). Ce format est optimis√©
// pour √™tre ing√©r√©, pars√© et visualis√© par des outils de monitoring et d'alerte.
type LogEntry struct {
	Timestamp string                 `json:"timestamp"`
	Level     LogLevel               `json:"level"`
	Message   string                 `json:"message"`
	Service   string                 `json:"service"`
	Error     string                 `json:"error,omitempty"`
	Metadata  map[string]interface{} `json:"metadata,omitempty"`
}

// EventEntry est la structure d'un √©v√©nement √©crit dans `tracker.events`.
// Elle impl√©mente le patron "Audit Trail" en capturant une copie fid√®le et immuable
// de chaque message re√ßu de Kafka, avec ses m√©tadonn√©es.
//
// Chaque entr√©e contient le message brut, le r√©sultat de la tentative de d√©s√©rialisation,
// et des informations contextuelles comme le topic, la partition et l'offset.
// Ce journal est la source de v√©rit√© pour l'audit, le rejeu d'√©v√©nements et le d√©bogage.
type EventEntry struct {
	Timestamp      string          `json:"timestamp"`
	EventType      string          `json:"event_type"`
	KafkaTopic     string          `json:"kafka_topic"`
	KafkaPartition int32           `json:"kafka_partition"`
	KafkaOffset    int64           `json:"kafka_offset"`
	RawMessage     string          `json:"raw_message"`
	MessageSize    int             `json:"message_size"`
	Deserialized   bool            `json:"deserialized"`
	Error          string          `json:"error,omitempty"`
	OrderFull      json.RawMessage `json:"order_full,omitempty"`
}

// Logger g√®re l'√©criture concurrente et s√©curis√©e dans un fichier de log.
type Logger struct {
	file    *os.File
	encoder *json.Encoder
	mu      sync.Mutex
}

// SystemMetrics collecte les m√©triques de performance du consommateur.
// L'acc√®s √† cette structure est prot√©g√© par un mutex pour garantir la s√©curit√© en concurrence.
type SystemMetrics struct {
	mu                sync.RWMutex
	StartTime         time.Time
	MessagesReceived  int64
	MessagesProcessed int64
	MessagesFailed    int64
	LastMessageTime   time.Time
}

var (
	logLogger    *Logger       // Logger pour `tracker.log` (observabilit√© syst√®me).
	eventLogger *Logger       // Logger pour `tracker.events` (tra√ßabilit√© des messages).
	systemMetrics = &SystemMetrics{StartTime: time.Now()}
)

// newLogger initialise un nouveau Logger pour un fichier donn√©.
func newLogger(filename string) (*Logger, error) {
	file, err := os.OpenFile(filename, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
	if err != nil {
		return nil, fmt.Errorf("impossible d'ouvrir le fichier %s: %v", filename, err)
	}
	return &Logger{
		file:    file,
		encoder: json.NewEncoder(file),
	}, nil
}

// initLoggers configure les deux loggers utilis√©s par l'application.
func initLoggers() (err error) {
	logLogger, err = newLogger("tracker.log")
	if err != nil {
		return err
	}
	eventLogger, err = newLogger("tracker.events")
	if err != nil {
		return err
	}
	logLogger.Log(LogLevelINFO, "Syst√®me de journalisation initialis√©", map[string]interface{}{
		"log_file":    "tracker.log",
		"events_file": "tracker.events",
	})
	return nil
}

// Log √©crit une entr√©e structur√©e dans `tracker.log`.
func (l *Logger) Log(level LogLevel, message string, metadata map[string]interface{}) {
	l.mu.Lock()
	defer l.mu.Unlock()

	entry := LogEntry{
		Timestamp: time.Now().UTC().Format(time.RFC3339),
		Level:     level,
		Message:   message,
		Service:   "order-tracker",
		Metadata:  metadata,
	}
	_ = l.encoder.Encode(entry)
}

// LogError est un raccourci pour √©crire un message d'erreur dans `tracker.log`.
func (l *Logger) LogError(message string, err error, metadata map[string]interface{}) {
	if metadata == nil {
		metadata = make(map[string]interface{})
	}
	entry := LogEntry{
		Timestamp: time.Now().UTC().Format(time.RFC3339),
		Level:     LogLevelERROR,
		Message:   message,
		Service:   "order-tracker",
		Error:     err.Error(),
		Metadata:  metadata,
	}
	l.mu.Lock()
	_ = l.encoder.Encode(entry)
	l.mu.Unlock()
}

// LogEvent √©crit un enregistrement complet de message dans `tracker.events`.
// Cette fonction est le c≈ìur de l'impl√©mentation du patron "Audit Trail".
// Elle est appel√©e pour CHAQUE message re√ßu, qu'il soit valide ou non, garantissant ainsi
// qu'aucune donn√©e entrante n'est perdue.
func (l *Logger) LogEvent(msg *kafka.Message, order *Order, deserializationError error) {
	l.mu.Lock()
	defer l.mu.Unlock()

	eventType := "message.received"
	deserialized := order != nil

	if deserializationError != nil {
		eventType = "message.received.deserialization_error"
	}

	event := EventEntry{
		Timestamp:      time.Now().UTC().Format(time.RFC3339),
		EventType:      eventType,
		KafkaTopic:     *msg.TopicPartition.Topic,
		KafkaPartition: msg.TopicPartition.Partition,
		KafkaOffset:    int64(msg.TopicPartition.Offset),
		RawMessage:     string(msg.Value),
		MessageSize:    len(msg.Value),
		Deserialized:   deserialized,
	}

	if deserialized {
		orderJSON, _ := json.Marshal(order)
		event.OrderFull = json.RawMessage(orderJSON)
	}

	if deserializationError != nil {
		event.Error = deserializationError.Error()
	}

	_ = l.encoder.Encode(event)
}

// Close ferme proprement les fichiers de log.
func (l *Logger) Close() {
	if l != nil {
		_ = l.file.Close()
	}
}

// recordMetrics met √† jour les compteurs de performance.
func (sm *SystemMetrics) recordMetrics(processed, failed bool) {
	sm.mu.Lock()
	defer sm.mu.Unlock()

	sm.MessagesReceived++
	if processed {
		sm.MessagesProcessed++
	}
	if failed {
		sm.MessagesFailed++
	}
	sm.LastMessageTime = time.Now()
}

// logPeriodicMetrics √©crit un r√©sum√© des m√©triques dans `tracker.log` √† intervalle r√©gulier.
// C'est un composant cl√© du patron "Application Health Monitoring".
// En publiant p√©riodiquement des indicateurs de performance (d√©bit, taux de succ√®s, uptime),
// elle permet de cr√©er des dashboards et des alertes pour surveiller la sant√© de l'application
// en temps quasi-r√©el.
func logPeriodicMetrics(stopChan <-chan struct{}) {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-stopChan:
			return // Arr√™t propre de la goroutine
		case <-ticker.C:
			systemMetrics.mu.RLock()
			uptime := time.Since(systemMetrics.StartTime)
			var successRate float64
			if systemMetrics.MessagesReceived > 0 {
				successRate = float64(systemMetrics.MessagesProcessed) / float64(systemMetrics.MessagesReceived) * 100
			}
			var messagesPerSecond float64
			if uptime.Seconds() > 0 {
				messagesPerSecond = float64(systemMetrics.MessagesReceived) / uptime.Seconds()
			}
			systemMetrics.mu.RUnlock()

			logLogger.Log(LogLevelINFO, "M√©triques syst√®me p√©riodiques", map[string]interface{}{
				"uptime_seconds":     uptime.Seconds(),
				"messages_received":  systemMetrics.MessagesReceived,
				"messages_processed": systemMetrics.MessagesProcessed,
				"messages_failed":    systemMetrics.MessagesFailed,
				"success_rate_percent": fmt.Sprintf("%.2f", successRate),
				"messages_per_second":  fmt.Sprintf("%.2f", messagesPerSecond),
			})
		}
	}
}

// main est le point d'entr√©e du programme consommateur.
//
// Son cycle de vie est le suivant :
// 1. Initialise les loggers pour `tracker.log` et `tracker.events`.
// 2. Configure et cr√©e une instance de consommateur Kafka.
// 3. S'abonne au topic 'orders'.
// 4. Lance une goroutine pour publier des m√©triques de performance toutes les 30 secondes.
// 5. Met en place la gestion des signaux d'arr√™t (Ctrl+C).
// 6. Entre dans une boucle de consommation pour lire les messages de Kafka :
//    a. Pour chaque message, tente de le d√©s√©rialiser.
//    b. Appelle `LogEvent` pour enregistrer le message dans `tracker.events` (succ√®s ou √©chec).
//    c. Met √† jour les m√©triques de performance.
//    d. Si la d√©s√©rialisation √©choue, loggue une erreur dans `tracker.log`.
//    e. Si elle r√©ussit, affiche les d√©tails de la commande dans la console.
// 7. Si un signal d'arr√™t est re√ßu, la boucle se termine.
// 8. Loggue un message final avec les statistiques compl√®tes de la session avant de s'arr√™ter.

// displayOrder affiche les d√©tails d'une commande format√©e dans la console.
func displayOrder(order *Order) {
	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Printf("üì¶ COMMANDE RE√áUE #%d (ID: %s)\n", order.Sequence, order.OrderID)
	fmt.Println(strings.Repeat("-", 80))
	fmt.Printf("Client: %s (%s)\n", order.CustomerInfo.Name, order.CustomerInfo.CustomerID)
	fmt.Printf("Statut: %s | Total: %.2f %s\n", order.Status, order.Total, order.Currency)
	fmt.Println("Articles:")
	for _, item := range order.Items {
		fmt.Printf("  - %s (x%d) @ %.2f %s\n", item.ItemName, item.Quantity, item.UnitPrice, order.Currency)
	}
	fmt.Println(strings.Repeat("=", 80))
}

// processMessage traite un message Kafka individuel.
// Il d√©s√©rialise, logue, et met √† jour les m√©triques.
func processMessage(msg *kafka.Message) {
	var order Order
	deserializationErr := json.Unmarshal(msg.Value, &order)

	// √âtape 1: Journaliser l'√©v√©nement (toujours).
	// Si la d√©s√©rialisation √©choue, nous passons `nil` pour `order` afin
	// que le journal d'audit refl√®te correctement l'√©chec.
	var orderForLog *Order
	if deserializationErr == nil {
		orderForLog = &order
	}
	eventLogger.LogEvent(msg, orderForLog, deserializationErr)

	// √âtape 2: Mettre √† jour les m√©triques et traiter le message
	if deserializationErr != nil {
		systemMetrics.recordMetrics(false, true)
		logLogger.LogError("Erreur de d√©s√©rialisation du message", deserializationErr, map[string]interface{}{
			"kafka_offset": msg.TopicPartition.Offset,
			"raw_message":  string(msg.Value),
		})
	} else {
		systemMetrics.recordMetrics(true, false)
		displayOrder(&order)
	}
}